{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "TRAIN_DATA = './data/train_data.csv'\n",
    "TRAIN_LABEL = './data/train_labels.csv'\n",
    "\n",
    "TEST_DATA = './data/test_data.csv'\n",
    "TEST_LABEL = './data/test_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "\n",
    "class CONFIG:\n",
    "\n",
    "    load_pickle = True\n",
    "    \n",
    "    is_toy = True\n",
    "    toy_size = 20\n",
    "    epochs = 20\n",
    "    validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Loading Spacy, may take a while\n",
      "INFO - Loading Spacy complete\n",
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    2.1.8                         \n",
      "Location         /opt/conda/lib/python3.7/site-packages/spacy\n",
      "Platform         Linux-4.9.184-linuxkit-x86_64-with-debian-buster-sid\n",
      "Python version   3.7.3                         \n",
      "Models                                         \n",
      "\n",
      "{'spaCy version': '2.1.8', 'Location': '/opt/conda/lib/python3.7/site-packages/spacy', 'Platform': 'Linux-4.9.184-linuxkit-x86_64-with-debian-buster-sid', 'Python version': '3.7.3', 'Models': ''}\n"
     ]
    }
   ],
   "source": [
    "def load_spacy():\n",
    "    print('INFO - Loading Spacy, may take a while')\n",
    "    nlp_spacy = spacy.load(\"en_core_web_md\")\n",
    "    print('INFO - Loading Spacy complete')\n",
    "    print(spacy.info())\n",
    "    return nlp_spacy\n",
    "\n",
    "nlp_spacy = None\n",
    "\n",
    "if nlp_spacy is None:\n",
    "    nlp_spacy = load_spacy()\n",
    "else:\n",
    "    print('INFO - Spacy already in place.')\n",
    "    print(spacy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOAD\n",
    "\n",
    "def data_load_files():\n",
    "    \n",
    "    print('INFO -- Loading data files')\n",
    "    train_label_df = pd.read_csv(TRAIN_LABEL, usecols=['document_name','is_fitara'])\n",
    "    train_data_df = pd.read_csv(TRAIN_DATA)\n",
    "    \n",
    "    test_label_df = pd.read_csv(TEST_LABEL, usecols=['document_name','is_fitara'])\n",
    "    test_data_df = pd.read_csv(TEST_DATA)\n",
    "    \n",
    "    if CONFIG.is_toy:\n",
    "        train_label_df = train_label_df.sample(n=CONFIG.toy_size)\n",
    "        train_data_df = train_data_df[train_data_df.document_name.isin(train_label_df.document_name.tolist())]\n",
    "    \n",
    "    return train_data_df, train_label_df, test_data_df, test_label_df\n",
    "\n",
    "def data_merge(data_df ,label_df):\n",
    "    \n",
    "    print('INFO -- merge data and label dfs')\n",
    "    df  = pd.merge (\n",
    "        label_df, \n",
    "        data_df, \n",
    "        on = 'document_name', \n",
    "        how = 'inner'\n",
    "    )\n",
    "    df.head()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def data_pre_processing(text):\n",
    "\n",
    "    print(\"INFO - processing - \" + text[:4])\n",
    "    texts = []\n",
    "    doc = nlp_spacy(text, disable=['parser', 'ner'])\n",
    "    tokens = [token for token in doc if not token.is_stop]\n",
    "    tokens = [token for token in tokens if not token.is_punct]\n",
    "    tokens = [token.lemma_.lower().strip() for token in tokens if token.lemma_ != '-PRON-']\n",
    "    tokens = ' '.join(tokens)\n",
    "#     print(tokens)\n",
    "    texts.append(tokens)\n",
    "    return pd.Series([texts, len(tokens)])\n",
    "\n",
    "\n",
    "\n",
    "def data_print_stats(df):\n",
    "    \n",
    "    print('INFO -- shape', df.shape)\n",
    "    print('INFO -- describe')\n",
    "    print(df.describe())\n",
    "    \n",
    "def data_get_train_df(df):\n",
    "    result = df['text'].apply(lambda x: data_pre_processing(x))\n",
    "    df['processed_text'], df['wc'] = result[0], result[1]\n",
    "    df['processed_text'] = df.apply(lambda row: row.processed_text[0], axis = 1) \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO -- Loading data files\n",
      "INFO -- merge data and label dfs\n"
     ]
    }
   ],
   "source": [
    "train_data_df, train_label_df, test_data_df, test_label_df = data_load_files()\n",
    "\n",
    "train_df = data_merge(train_data_df, train_label_df)\n",
    "test_df = test_data_df\n",
    "\n",
    "# data_print_stats(train_df)\n",
    "# data_print_stats(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - processing - AMEN\n",
      "INFO - processing - Limi\n",
      "INFO - processing - WD 1\n",
      "INFO - processing - PART\n",
      "INFO - processing - STAT\n",
      "INFO - processing - 52.2\n",
      "INFO - processing - - 1 \n",
      "INFO - processing - The \n",
      "INFO - processing - STAT\n",
      "INFO - processing - - 1 \n",
      "INFO - processing - 52.2\n",
      "INFO - processing - Depa\n",
      "INFO - processing - 52.2\n",
      "INFO - processing - Ofﬁc\n",
      "INFO - processing - PART\n",
      "INFO - processing - 5127\n",
      "INFO - processing - 52.2\n",
      "INFO - processing - Stat\n",
      "INFO - processing - PART\n",
      "INFO - processing - 52.2\n"
     ]
    }
   ],
   "source": [
    "train_df = data_get_train_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>is_fitara</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DHHS-NIHAO2016038-amd3.pdf</td>\n",
       "      <td>Yes</td>\n",
       "      <td>AMENDMENT OF SOLICITATION / MODIFICATION OF \\n...</td>\n",
       "      <td>amendment solicitation modification  contract ...</td>\n",
       "      <td>759107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200041I_Limited_Source_Justification.pdf</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Limited Source Justiﬁcation\\n\\n \\n\\n \\n\\n\"Sour...</td>\n",
       "      <td>limited source justiﬁcation  source selection ...</td>\n",
       "      <td>5652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wage_Determination_2015-2103.pdf</td>\n",
       "      <td>No</td>\n",
       "      <td>WD 15-2103 (Rev.-2) was first posted on www.wd...</td>\n",
       "      <td>wd 15 2103 rev.-2 post www.wdol.gov 01/05/2016...</td>\n",
       "      <td>22719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FAR_52-212-5.pdf</td>\n",
       "      <td>No</td>\n",
       "      <td>PART 52 Solicitation Provisinns and Comract Cl...</td>\n",
       "      <td>52 solicitation provisinns comract clause page...</td>\n",
       "      <td>13965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOW_ServiceContract_AirPollutionSystem_NOIRMLC...</td>\n",
       "      <td>No</td>\n",
       "      <td>STATEMENT OF WORK Envitech Air Pollution Contr...</td>\n",
       "      <td>statement work envitech air pollution control ...</td>\n",
       "      <td>2656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       document_name is_fitara  \\\n",
       "0                         DHHS-NIHAO2016038-amd3.pdf       Yes   \n",
       "1          1200041I_Limited_Source_Justification.pdf       Yes   \n",
       "2                   Wage_Determination_2015-2103.pdf        No   \n",
       "3                                   FAR_52-212-5.pdf        No   \n",
       "4  SOW_ServiceContract_AirPollutionSystem_NOIRMLC...        No   \n",
       "\n",
       "                                                text  \\\n",
       "0  AMENDMENT OF SOLICITATION / MODIFICATION OF \\n...   \n",
       "1  Limited Source Justiﬁcation\\n\\n \\n\\n \\n\\n\"Sour...   \n",
       "2  WD 15-2103 (Rev.-2) was first posted on www.wd...   \n",
       "3  PART 52 Solicitation Provisinns and Comract Cl...   \n",
       "4  STATEMENT OF WORK Envitech Air Pollution Contr...   \n",
       "\n",
       "                                      processed_text      wc  \n",
       "0  amendment solicitation modification  contract ...  759107  \n",
       "1  limited source justiﬁcation  source selection ...    5652  \n",
       "2  wd 15 2103 rev.-2 post www.wdol.gov 01/05/2016...   22719  \n",
       "3  52 solicitation provisinns comract clause page...   13965  \n",
       "4  statement work envitech air pollution control ...    2656  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO -- shape (20, 5)\n",
      "INFO -- describe\n",
      "                  wc\n",
      "count      20.000000\n",
      "mean    77066.450000\n",
      "std    175351.578623\n",
      "min       542.000000\n",
      "25%      6036.000000\n",
      "50%     13725.000000\n",
      "75%     40504.250000\n",
      "max    759107.000000\n"
     ]
    }
   ],
   "source": [
    "data_print_stats(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
